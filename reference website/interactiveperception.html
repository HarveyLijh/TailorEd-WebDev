			<!DOCTYPE html>
			<html>
			  <head>
				<title>Interactive Perception and Robot Learning Lab - Interactive Perception</title>
				
				<meta name="author" content="Jeannette Bohg">
				<meta name="description" content="Interactive Perception and Robot Learning Lab-Home">
				<meta name="keywords" content="Interactive Perception, Robotics, Manipulation, Grasping, Machine Learning, Multi-Modality">

				<meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">

				<link href="assets/css/font-awesome.min.css" rel="stylesheet">
				<link href="assets/css/jquery-ui-effects.min.css" rel="stylesheet">
				<link href="assets/css/bootstrap.min.css" rel="stylesheet">
				<link href="assets/css/styles.css" rel="stylesheet">
				<link href="assets/css/header.css" rel="stylesheet">
				<link href="assets/css/footer.css" rel="stylesheet">
				<link href="assets/css/section.css" rel="stylesheet">
				<link href="assets/css/slideout.css" rel="stylesheet">
				<link href="assets/css/menu-nav.css" rel="stylesheet">
				<link href="assets/css/mobile-nav.css" rel="stylesheet">
			  </head>


			  <body id="page-top" data-spy="scroll" data-target=".navbar-top" data-header="true">

				<!-- mobile menu -->
				<nav id="menu" class="menu">  
				  <section class="menu-section">
				<ul class="menu-section-list">
				  <li><a href class="page-scroll">Home</a></li>
				  <li><a href="#news" class="page-scroll">News</a></li>
				  <li><a href="#projects" class="page-scroll">Projects</a></li>
				  <li><a href="#people" class="page-scroll">People</a></li>
				  <li><a href="#teaching" class="page-scroll">Teaching</a></li>
				  <li><a href="#contact" class="page-scroll">Contact</a></li>
				  <li><a href="publications.html" class="page-scroll">Publications</a></li>
				  
				</ul>
				  </section>
				</nav>

				<header class="header-wrapper fixed">

				  <!-- navbar -->
				  <nav id="navbar" class="navbar-scroll navbar cv-navbar navbar-fixed-top" data-spy="affix" data-offset-top="100">
				<div class="container">
				  
				  <div id="navbar-container" class="cv-navbar-container">
					<div class="navbar-header">
					  Stanford IPRL Lab
					</div>
					<div id="navbar" class="pull-right">
					  <ul class="nav navbar-nav cv-navbar-list hidden-md hidden-sm hidden-xs">
					<li><a href="#home" class="page-scroll">Home</a></li>
					<li class="hidden-sm hidden-xs"><a href="#news" class="page-scroll">News</a></li>
					<li class="hidden-sm hidden-xs"><a href="#projects" class="page-scroll">Projects</a></li>
					<li class="hidden-sm hidden-xs"><a href="#people" class="page-scroll">People</a></li>
					<li class="hidden-sm hidden-xs"><a href="#teaching" class="page-scroll">Teaching</a></li>
					<li class="hidden-sm hidden-xs"><a href="#contact" class="page-scroll">Contact</a></li>
					<li class="hidden-sm hidden-xs"><a href="publications.html" class="page-scroll">Publications</a></li>
					  </ul>
					  
					  <ul class="nav hidden-lg">
					<li class="hidden-lg">
					  <button type="button" class="js-slideout-toggle btn btn-mobile-menu">
						<i class="fa fa-bars" aria-hidden="true"></i>
					  </button>
					</li>
					  </ul> 

					</div> 
				  </div>
				</div>
				  </nav>
				</header>

				<main id="main" class="panel main-panel">

				  <!-- header image -->
				  <div class="section-header">
				<div class="text-ribbon text-ribbon-mobile">
				  <div class="container">
					<h1>
					  <strong>Interactive Perception</strong>
					</h1>
				  </div>
				</div>
				  </div>

				  <!-- content -->
				  <div id="abstract" name="abstract" class="linked-section">
				<div class="container">

				  <!--h1 class="section-header-h1">Where</h1-->
				  
				  <h1 class="section-header-h1" id="home">Overview </h1> 

				  <p class="lead ">
				  	<img src="assets/images/GibsonHighResSmall.png" alt width="400" style="float:right; margin-left: 20px">
				  	A robot has different means to actively explore and better understand its environment. It can look around and fixate on interesting areas, it can ask someone for more information or it can physically interact with the environment to explore and better understand its structure. 
				  	<br> <br>
				  	Feedback received in this manner provides informative sensory signals that would otherwise not be present and are especially important for manipulation. Furthermore, understanding the signal in the context of the action that has produced it facilitates interpretation and prediction of the signal.
				  	<br> <br>
				  	 Check out the papers below to get an idea on how we implemented this concept on robots.
				  	 Read more about Interactive Perception in this comprehensive <strong><a href="https://arxiv.org/pdf/1604.03670.pdf">survey!</a></strong>
				  </p>
				</div>
				  </div>

				
		<!-- content -->
		<div id="visionandtouch" name="publications" class="linked-section section-grey">
			<div class="container">

				<div class="margin-bottom-50">
                    <h1 class="section-header-h1 margin-bottom-20">Fusing Vision, Touch and Motion</h1>
                    <p class="margin-bottom-20">
		            Lee, M.*, Zhu, Y.*, Zachares, P., Tan, M., Srinivasan, K., Savarese, S., Fei-Fei, L., Garg, A., Bohg, J. <strong><u><a href="https://arxiv.org/abs/1907.13098">Making Sense of Vision and Touch: Learning Multimodal Representations for Contact-Rich Tasks.</a></u></strong> 
			    Transactions in Robotics (Accepted for Publication). 2019.</p>
                    <p class="margin-bottom-20">
		            Lee, M., Zhu, Y., Srinivasan, K., Shah, P., Savarese, S., Fei-Fei, L., Garg, A., Bohg, J. <strong><u><a href="https://sites.google.com/view/visionandtouch">Making Sense of Vision and Touch: Self-Supervised Learning of Multimodal Representations for Contact-Rich Tasks.</a></u></strong> Accepted at ICRA '19. 
		            <span style="color:#FA492B">Best Paper Award and Finalist for Best Paper Award on Cognitive Robotics.</span>
		        	</p>
		        	 <p class="margin-bottom-20">
                        Shao, L., Shah, P., Dwaracherla, V., Bohg, J. <strong><u><a href="https://arxiv.org/pdf/1804.05195">Motion-based Object Segmentation based on Dense RGB-D Scene Flow</a></u></strong> 
                        <em>IEEE Robotics and Automation Letters</em>, 3(4):3797-3804, IEEE, IEEE/RSJ International Conference on Intelligent Robots and Systems, October 2018
                    </p>
					<p class="margin-bottom-20">
						Ilonen, J., Bohg, J., Kyrki, V. <u><strong><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6631074">Fusing visual and tactile sensing for 3-D object reconstruction while grasping</a></strong></u> In <em>IEEE International Conference on Robotics and Automation (ICRA)</em>, pages: 3547-3554, 2013 
					</p>
					<p class="margin-bottom-20">
						Illonen, J., Bohg, J., Kyrki, V. <u><strong><a href="http://journals.sagepub.com/doi/pdf/10.1177/0278364913497816">3-D Object Reconstruction of Symmetric Objects by Fusing Visual and Tactile Sensing</a></strong></u> <em>The International Journal of Robotics Research</em>, 33(2):321-341, Sage, October 2013.
					</p>
					<p class="margin-bottom-20">
						Bohg, J., Johnson-Roberson, M., Bj&ouml;rkman, M., Kragic, D. <u><strong><a href="https://am.is.tuebingen.mpg.de/uploads_file/attachment/attachment/307/2010_IROS_bjbk_camred.pdf">Strategies for multi-modal scene exploration</a></strong></u> In <em>Intelligent Robots and Systems (IROS), 2010 IEEE/RSJ International Conference on</em>, pages: 4509-4515, October 2010.
					</p>
                </div>
            </div>
         </div>

			<div id="saliency" name="saliency" class="linked-section">
			  <div class="container">
				<div class="margin-bottom-50">
                    <h1 class="section-header-h1 margin-bottom-20">Top-Down and Bottom-Up Visual Attention</h1>
                     <p class="margin-bottom-20">
                    	Kloss, A., Kappler, D., Lensch, H. P. A., Butz, M. V., Schaal, S., Bohg, J. <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7759770"><u><strong>  Learning Where to Search Using Visual Attention</strong></u></a> <em>Proceedings of the IEEE/RSJ Conference on Intelligent Robots and Systems</em>, IEEE, IROS, October 2016
                    </p>
                    <p class="margin-bottom-20">
						Gratal, X., Bohg, J., Bj&ouml;rkman, M., Kragic, D. <u><strong><a href="https://am.is.tuebingen.mpg.de/uploads_file/attachment/attachment/309/2010_IROSWS_gbbrk.pdf">Scene Representation and Object Grasping Using Active Vision</a></strong></u> In <em>IROS&rsquo;10 Workshop on Defining and Solving Realistic Perception Problems in Personal Robotics</em>, October 2010 
					</p>
					<p class="margin-bottom-20">
						Johnson-Roberson, M., Bohg, J., Bj&ouml;rkman, M., Kragic, D. <u><strong><a href="https://am.is.tuebingen.mpg.de/uploads_file/attachment/attachment/214/2010_IROS_jbbk.pdf">Attention-based active 3D point cloud segmentation</a></strong></u> In <em>Intelligent Robots and Systems (IROS), 2010 IEEE/RSJ International Conference on</em>, pages: 1165-1170, October 2010.
					</p>
                </div>
			  </div>
			</div>

			<div id="activelearning" name="activelearning" class="linked-section section-grey">
			  <div class="container">
			  	<div class="margin-bottom-50">
                    <h1 class="section-header-h1 margin-bottom-20">Active Learning and Information Gathering</h1>
                     <p class="margin-bottom-20">
                        Shao, L., Migimatsu, T., Bohg, J. 
                        <strong><u><a href="https://sites.google.com/view/scaffoldlearning">Learning to Scaffold the Development of Robotic Manipulation Skills</a></u></strong> 
                        Submitted to ICRA. 2020. 
                    </p>
                    <p class="margin-bottom-20">
						Marco, A., Hennig, P., Bohg, J., Schaal, S., Trimpe, S. <u><strong><a href="https://arxiv.org/pdf/1605.01950">Automatic LQR Tuning Based on Gaussian Process Global Optimization</a></strong></u> In <em>Proceedings of the IEEE International Conference on Robotics and Automation (ICRA)</em>, IEEE International Conference on Robotics and Automation, May 2016 
					</p>
					<p class="margin-bottom-20">
						Toussaint, M., Ratliff, N., Bohg, J., Righetti, L., Englert, P., Schaal, S. <u><strong><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6942539">Dual Execution of Optimized Contact Interaction Trajectories</a></strong></u> In <em>Proceedings of the International Conference on Intelligent Robots and Systems</em>, Chicago, IL, October 2014. 
					</p>
					<p class="margin-bottom-20">
						Johnson-Roberson, M., Bohg, J., Skantze, G., Gustafson, J., Carlson, R., Rasolzadeh, B., Kragic, D. <u><strong><a href="http://www.speech.kth.se/prod/publications/files/3464.pdf">Enhanced visual scene understanding through human-robot dialog</a></strong></u> In <em>Intelligent Robots and Systems (IROS), 2011 IEEE/RSJ International Conference on</em>, pages: 3342-3348, 2011.
					</p>
                </div>
			  </div>
			</div>


			<div id="cognition" name="cognition" class="linked-section">
			  <div class="container">
			  	<div class="margin-bottom-50">
                    <h1 class="section-header-h1 margin-bottom-20">Cognitive Science</h1>
                    <p class="margin-bottom-20">
                    	Bohg, J., Hausman, K., Sankaran, B., Brock, O., Kragic, D., Schaal, S., Sukhatme, G.  <a href="https://arxiv.org/pdf/1604.03670"><u><strong> Interactive Perception: Leveraging Action in Perception and Perception in Action</strong></u></a> <em>IEEE Transactions on Robotics</em>, 33, pages: 1273-1291, December 2017.
                    </p>
					<p class="margin-bottom-20">
                    	Dominey, P. F., Prescott, T. J., Bohg, J., Engel, A. K., Gallagher, S., Heed, T., Hoffmann, M., Knoblich, G., Prinz, W., Schwartz, A. <a href="https://philpapers.org/archive/DOMIOA.pdf"><u><strong> Implications of Action-Oriented Paradigm Shifts in Cognitive Science </strong></u></a> In <em>The Pragmatic Turn - Toward Action-Oriented Views in Cognitive Science</em>, 18, pages: 333-356, 20, Str&uuml;ngmann Forum Reports, vol. 18, J. Lupp, series editor, (Editors: Andreas K. Engel and Karl J. Friston and Danica Kragic), The MIT Press, 18th Ernst Strungmann Forum, May 2016.
                    </p>
                    <p class="margin-bottom-20">
                    	Bohg, J., Kragic, D. <a href="https://am.is.tuebingen.mpg.de/uploads_file/attachment/attachment/285/SFR18_18_Bohg_and_Kragic.pdf"><u><strong> Learning Action-Perception Cycles in Robotics: A Question of Representations and Embodiment.</strong></u></a> In <em>The Pragmatic Turn - Toward Action-Oriented Views in Cognitive Science</em>, 18, pages: 333-356, 20, Str&uuml;ngmann Forum Reports, vol. 18, J. Lupp, series editor, (Editors: Andreas K. Engel and Karl J. Friston and Danica Kragic), The MIT Press, 18th Ernst Strungmann Forum, May 2016.
                    </p>
                </div>
			  </div>
			</div>



			<!-- footer -->
			<div class="footer">
			  <div class="container">
				<div class="row">
				  <div class="col-md-12">
				<span class="custom-fa-icon"><i class="fa fa-copyright" aria-hidden="true"></i></span> Interactive Perception and Robot Learning Lab 2018
				  </div>
				</div>
			  </div>
			</div>
			</main>

			<script src="assets/js/jquery-3.1.1.min.js"></script>
			<script src="assets/js/jquery-ui-effects.min.js"></script>
			<script src="assets/js/bootstrap.min.js"></script>
			<script src="assets/js/init.js"></script>
			<script src="assets/js/slideout.min.js"></script>


			</body>
			</html>


